agent:
  name: maddpg
  _target_: model.maddpg.MADDPG
  params:
    obs_dim: ???
    action_dim: ???
    action_range: ???
    agent_index: ???
    hidden_dim: 64
    device: ${device}
    discrete_action_space: ${discrete_action_space}
    batch_size: 256
    lr: 0.001
    tau: 0.01
    gamma: 0.95
    critic:
      input_dim: ???
env: cramped_room_tomato
episode_length: 500
discrete_action_space: true
experiment: vanilla
seed: 0
num_seed_steps: 10000
num_train_steps: 10000000.0
replay_buffer_capacity: 50000.0
eval_frequency: 10000
num_eval_episodes: 3
common_reward: true
ou_exploration_steps: ${num_train_steps}
ou_init_scale: 0.3
ou_final_scale: 0
adversarial: Trues
device: cpu
log_frequency: 5000
log_save_tb: true
save_video: true
render: false
save_model: false
save_replay_buffer: false
alg_type: multiTravos
lazy_agent: true
adv_agent: true
both: false
advers_prob: 0.5
lazy_prob: 0.5
discretize_trust: true
adaptive_discretize: false
include_in:
- true
- true
- true
- true
one_hot_encode: true
include_thres: true
